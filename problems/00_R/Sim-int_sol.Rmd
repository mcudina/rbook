The idea here is to use the "fundamental theorem of statistics"
$$ \EE[ g(X) ] = \int g(x)\, f_X(x)\, dx $$
where $f_X$ is the pdf of $X$ and $g$ is any reasonably well-behaved function. 
Normally, one would use the integral on the right to compute the expectation
on the left. We are flipping the logic, and using the expectation 
(which we can approximate via Monte Carlo) to estimate the integral on the 
right. 

a) 
    We pick $g(x) = \cos(x)$ and $X$ a r.v. with a uniform distribution on $(0,1)$, so that $f_X(x) = 1$ for $x\in (0,1)$ and $0$ otherwise:
  

    ```{r}
    nsim=10000
    x = runif(nsim)
    y = cos(x)
    mean(y)
    ```
    
    For comparison, the exact value of the integral is $\sin(1) \approx 0.841471$. 
  
b) 
    We cannot use the uniform distribution anymore, because the limits of integration are $\pm \infty$. Part of the expression inside the integral can be recognized as a (standard) normal density, so we take $X \sim N(0,1)$ and $g(x) =
    1/(1+x^4)$
    
    
    ```{r}
    nsim=10000
    x = rnorm(nsim)
    y = 1/(1+x^4)
    mean(y)
    ```
    
    The "exact" value (i.e., very precise approximation to this integral obtained using another numerical method) is $0.676763$. 
  
c) 
    We integrate $g(x) = \exp(-x^3)$ against the exponential pdf $f_X(x) = \exp(-x)$, for $x>0$: 
  
    ```{r}
    nsim=10000
    x=rexp(nsim)
    y=exp(-x^3)
    mean(y)
    ```
  
    A close approximation of the true value is $0.56889$.
  
d) 
    In this case, a possible choice of the distribution for $X$ is the Cauchy distribution (no worries if you never heard about it), whose pdf is $f_X(x) = \frac{1}{\pi(1+x^2)}$, so that $g(x) = \pi \cos(x^2)$:
  
    ```{r}
    nsim=10000
    x=rcauchy(nsim)
    y = pi*cos(x^2)
    mean(y)
    ```
  
    The "exact" value is $1.30561$. 
  
